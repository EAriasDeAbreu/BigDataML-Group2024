---
title: "Big Data & Machine Learning 2024-2"
author: "Edmundo Arias De Abreu"
output:
  rmdformats::robobook:
    self_contained: true
    thumbnails: true
    lightbox: true
    gallery: false
    highlight: tango
    code_folding: show
---

# Problem Set #1: Predicting Income

### Members
- Edmundo Arias De Abreu - 202110688
- Lucia Maldonado - `add code`
- Juan Diego Heredia - `add code`

#### Date: August 9th, 2024

----

In the public sector, accurate reporting of individual income is critical for computing taxes. However, tax fraud of all kinds has always been a significant issue. According to the Internal Revenue Service (IRS), about 83.6% of taxes are paid voluntarily and on time in the US[^1]. One of the causes of this gap is the under-reporting of incomes by individuals. An income predicting model could potentially assist in flagging cases of fraud that could lead to the reduction of the gap. Furthermore, an income prediction model can help identify vulnerable individuals and families that may need further assistance.

The objective of the problem set is to apply the concepts we learned using "real" world data. For that, we are going to scrape from the following website: [https://ignaciosarmiento.github.io/GEIH2018_sample/](https://ignaciosarmiento.github.io/GEIH2018_sample/). This website contains data for Bogotá from the 2018 _Medición de Pobreza Monetaria y Desigualdad Report_ that takes information from the GEIH.

## 1.1. General Instructions

The main objective is to construct a model of individual hourly wages:

$$
w = f(X) + u
$$

where \( w \) is the hourly wage, and \( X \) is a matrix that includes potential explanatory variables/predictors. In this problem set, we will focus on \( f(X) = X\beta \).

The final document, in .pdf format, must contain the following sections:

1. **Introduction**. The introduction briefly states the problem and if there are any antecedents. It briefly describes the data and its suitability to address the problem set question. It contains a preview of the results and main takeaways.

---

**Answer**

`TODO`


---


2. **Data**. We will use data for Bogotá from the 2018 _Medición de Pobreza Monetaria y Desigualdad Report_ that takes information from the GEIH.

The dataset contains all individuals sampled in Bogotá and is available at the following website: [https://ignaciosarmiento.github.io/GEIH2018_sample/](https://ignaciosarmiento.github.io/GEIH2018_sample/). To obtain the data, you must scrape the website.

In this problem set, we will focus only on employed individuals older than eighteen (18) years old. Restrict the data to these individuals and perform a descriptive analysis of the variables used in the problem set. Keep in mind that in the data, there are many observations with missing data or 0 wages. I leave it to you to find a way to handle this data.

When writing this section up, you must:

1. **Describe the data briefly**, including its purpose, and any other relevant information.
2. **Describe the process of acquiring the data** and if there are any restrictions to accessing/scraping these data.
3. **Describe the data cleaning process**.
4. **Descriptive analysis of the variables** included in your analysis. At a minimum, you should include a descriptive statistics table with its interpretation. However, I expect a deep analysis that helps the reader understand the data, its variation, and the justification for your data choices. Use your professional knowledge to add value to this section. Do not present it as a "dry" list of ingredients.


---

**Answer**

### Part 1: Extracting data
I will use standard webscraping methods to acces the data and store it in a dataframe. The data will be stored in a dataframe called `df`.

#### Set-up
```{r packages, message=FALSE, echo=TRUE, results='hide'}
rm(list = ls())
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
options(repos = c(CRAN = "https://cloud.r-project.org"))

# install and load required packages
packages <- c("tidyverse", "ggplot2", "stargazer", "rvest", "dplyr", "httr", "boot", "broom")
invisible(lapply(packages, function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) install.packages(pkg)
  library(pkg, character.only = TRUE)
}))
```

Next we will read the webpage by accessing its HTML contents.

```{r read_html, message=FALSE, echo=TRUE, results='hide'}
# function to scrape data for a single page dynamically
scrape_page <- function(url) {
  response <- GET(url)
  if (status_code(response) != 200) {
    stop(paste("Failed to retrieve page:", url))
  }
  
  content <- content(response, "text")
  page <- read_html(content)
  include_element <- html_node(page, "[w3-include-html]")
  include_url <- html_attr(include_element, "w3-include-html")
  full_include_url <- paste0("https://ignaciomsarmiento.github.io/GEIH2018_sample/", include_url)
  
  included_content <- read_html(full_include_url)
  df_page <- html_node(included_content, "table") %>% html_table()
  
  return(df_page)
}

```

Now, we'll use our `scrape_page` function to scrape data from all 10 pages:

```{r extract_data, message=FALSE, echo=TRUE, results='hide'}
base_url <- "https://ignaciomsarmiento.github.io/GEIH2018_sample/page"
df_list <- lapply(1:10, function(i) {
  url <- paste0(base_url, i, ".html")
  df_page <- scrape_page(url)
  print(paste("Successfully scraped page", i))
  return(df_page)
})

# append dataframes
df <- do.call(rbind, df_list)

print(paste("Dimensions of the combined dataframe:", paste(dim(df), collapse = " x ")))


```

That's it! Now we can view the `df`. The trick was that the webpage used a technique called *dynamic content loading*, where the main content (in this case, the data table) is loaded after the initial page load. Ignacio surely designed the page to load its main content (the data table) dynamically after the initial page load. This is often used to improve page load times or to separate content management, but it breaks simple web scraping techniques for various reasons (e.g., 1) the data is loaded asynchronously, meaning it's not present in the initial HTML response, hence Simple GET requests only retrieve the initial HTML, missing the dynamically loaded content; 2) dynamic content is often loaded via JavaScript-- Basic web scraping tools, which only parse HTML, can't execute JavaScript; 3) the content might be loaded with a delay, making it difficult to time when to scrape the page).

Here was my solution

1. First, fetch the main page.
2. Then, locate the element with the `w3-include-html` attribute, which indicates where dynamic content should be inserted
3. Extract the URL of the included HTML file from this attribute.
4. Fetching and parsing this included file separately
5. Repeat for all 10 data chunks


```{r view_df, message=FALSE, echo=TRUE}
# here's how the data looks like
head(df, n = 10)
```


---






[^1]: IRS, Tax Gap Estimates, 2021.

## 3. Age-Wage Profile

A great deal of evidence in labor economics suggests that the typical worker’s age-wage profile has a predictable path: *“Wages tend to be low when the worker is young; they rise as the worker ages, peaking at about age 50; and the wage rate tends to remain stable or decline slightly after age 50.”*

In this subsection, we are going to estimate the Age-Wage profile for the individuals in this sample:

$$
\log(w) = \beta_1 + \beta_2 \text{Age} + \beta_3 \text{Age}^2 + u \tag{3.1}
$$

When presenting and discussing your results, include:

- A regression table.
- An interpretation of the coefficients and their significance.
- A discussion of the model’s in-sample fit.
- A plot of the estimated age-earnings profile implied by the above equation. Including a discussion of the "peak age" with its respective confidence intervals. (Note: Use bootstrap to construct the confidence intervals.)


---

**Answer**

Let's first keep individuals over 18 years of `age` and that are employed (e.g.,
`acu=1`). 

```{r age_wage, echo=TRUE, message=FALSE, results='hide'}
df <- df[df$age > 18 & df$ocu == 1, ]
names(df) <- make.names(names(df), unique = TRUE) # set df names

```

Next, let's deal with $0$ wages. Given that we will estimate the response using 
a logarithmic transformation anyway, let's replace $0$ wages with a small value.
We take the variable `y_ingLab_m` as the wage variable-- that is, nominal monthly salary for all occupations.
We also drop missing wage values from dataset.

```{r log_wages, echo=TRUE, message=FALSE, results='hide'}
df <- df %>%
  filter(!is.na(y_ingLab_m), !is.na(age)) %>%
  mutate(log_wage = log(y_ingLab_m + 1))

```
    
    
Now we are ready to fit the model. Specifically, we estimate the model (1.1) by OLS
```{r fit_model}
model <- lm(log_wage ~ age + I(age^2), data = df)
print(summary(model))
```

Next, let's apply the **Bootstrap** to estimate standard errors. The bootstrap is a resampling method that estimates the sampling distribution of a statistic by repeatedly resampling with replacement from the data. We will use the `boot` package to do this.

For convenience, we define a function `boot_fn` that fits the model and returns the coefficients and the peak age. We also define a function `calc_peak_age` that calculates the peak age given the coefficients of the model. I'll show the math behind this.

We start with the quadratic model for the age-wage profile:
$$\log(w) = \beta_1 + \beta_2 \cdot Age + \beta_3 \cdot Age^2 + u$$

where $w$ is the wage, $Age$ is the worker's age, and $u$ is the error term.

The peak age is the point at which wages reach their maximum. At this point, the slope of the age-wage profile is zero - wages are no longer increasing with age, but haven't yet started to decrease. Hence, to find the peak age, we need to: 1) find the derivative of $\log(w)$ with respect to $Age$, 2) set this derivative to zero and solve for $Age$.

For 1) we get

$$\frac{\partial\log(w)}{\partial Age} = \beta_2 + 2\beta_3 \cdot Age$$

setting this to zero, we get
$$\begin{align}
\beta_2 + 2\beta_3 \cdot Age &= 0 \\
2\beta_3 \cdot Age &= -\beta_2 \\
Age &= -\frac{\beta_2}{2\beta_3}
\end{align}$$
Therefore, the formula for the peak age is:
$$Peak Age = -\frac{\beta_2}{2\beta_3}$$
This expression falls in line with intuition and overall economic theory. Early in a career (young age), the positive linear term ($\beta_2 \cdot Age$) dominates, representing increasing wages due to factors like experience and skill accumulation. Later in a career (older age), the negative quadratic term ($\beta_3 \cdot Age^2$) becomes more influential, possibly representing factors like skill obsolescence or reduced productivity.

We implement this into functions in $\mathtt{R}$

```{r bootstrap, echo=TRUE, message=FALSE, results='hide'}
# Bootstrap
boot_fn <- function(data, indices) {
  d <- data[indices,]
  fit <- lm(log_wage ~ age + I(age^2), data = d)
  coef <- coef(fit)
  peak_age <- -coef[2] / (2 * coef[3])
  return(c(coef, peak_age = peak_age))
}

# peak age
calc_peak_age <- function(data, indices) {
  d <- data[indices,]
  model <- lm(log_wage ~ age + I(age^2), data = d)
  coef <- coef(model)
  peak_age <- -coef[2] / (2 * coef[3])
  return(peak_age)
}

# do bootstrap
set.seed(555)
boot_results <- boot(data = df, statistic = boot_fn, R = 1000)

# bootstrap se's
boot_se <- apply(boot_results$t, 2, sd)


```

I can next present this in a regression table, while annexing the estimated 'peak age' and its confidence intervals (via the bootstrap).

```{r reg_table, echo=TRUE, message=FALSE}

# reg table
stargazer(model, se = list(boot_se), type = "text", 
          title = "Age-Wage Profile Regression Results",
          column.labels = c("Coefficients", "Bootstrap SE"))

# peak age & CI's
original_peak_age <- -coef(model)[2] / (2 * coef(model)[3])
ci_peak <- quantile(boot_results$t[,4], c(0.025, 0.975))

cat("\nPeak Age Analysis:\n")
cat("Estimated Peak Age:", round(original_peak_age, 2), "\n")
cat("95% CI for Peak Age:", round(ci_peak[1], 2), "to", round(ci_peak[2], 2), "\n\n")

```


Finally, we can visualize this relationship by plotting the estimated age-wage profile. We can also include the peak age and its confidence intervals to be clear.

```{r plot, echo=TRUE, message=FALSE, fig.width=10, fig.height=6, out.width="100%"}

# plot
new_data <- data.frame(age = seq(min(df$age), max(df$age), length.out = 100))
new_data$predicted_log_wage <- predict(model, newdata = new_data)

p <- ggplot(df, aes(x = age, y = log_wage)) +
  geom_point(alpha = 0.1) +
  geom_line(data = new_data, aes(y = predicted_log_wage), color = "red") +
  geom_vline(xintercept = original_peak_age, color = "blue", linetype = "dashed") +
  geom_vline(xintercept = ci_peak[1], color = "green", linetype = "dashed") +
  geom_vline(xintercept = ci_peak[2], color = "green", linetype = "dashed") +
  # Add horizontal line at the estimated peak wage
  geom_hline(yintercept = predict(model, newdata = data.frame(age = original_peak_age)), 
             color = "blue", linetype = "dashed") +
  # Add text annotation for peak age
  annotate("text", x = original_peak_age, y = min(df$log_wage), 
           label = paste("Peak Age:", round(original_peak_age, 1)), 
           vjust = -0.5, hjust = 1.1, color = "blue") +
  labs(title = "Age-Wage Profile",
       x = "Age", y = "Log Wage",
       caption = "Blue dashed lines: Estimated peak age and wage\nGreen dashed lines: 95% CI") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))  # Center the title

# Display the plot
print(p)

```


---


















